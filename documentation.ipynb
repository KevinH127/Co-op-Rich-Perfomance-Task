{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Co-op RIch Perfomance Task\n#### At U+Education I had to make a Web Crawling Application. Using Python, I had to research libraries and come up with innovative ways to make this application. This is my documentation of my thought process throughout making the application, and also an explaination on how to make it.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Goal\n#### The goal of this application is to scrape information off the web automatically, minimizing human interaction. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1\n#### First, we need to find and import libraries that can, 1. Open a browser, 2. Parse the HTML code and 3. Read the HTML code.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "I did some research and found the best library to work with for me was Selenium. Selenium would allow me to use a browser through Python, parse the HTML code from the browser, and also read the HTML code and turn the elements into text. Therefore, in the code, I imported Selenium's Chrome Browser and it's \"By\" function.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from selenium.webdriver import Chrome\nfrom selenium.webdriver.common.by import By",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'selenium'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chrome\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2\n#### We then need to initialize variables for the Browser, our URL, and open the Chrome browser.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For the browser, we can initialize a variable called \"driver\" with the Chrome() function. For this application, we will scrape information from the following link, https://westernu.campuslabs.ca/engage/organizations, and scrape the names and emails of all the organizations.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Initialize variables\ndriver = Chrome()\nURL = 'https://westernu.campuslabs.ca/engage/organizations'\n\n# Open the browser\ndriver.get(URL)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'Chrome' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize variables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mChrome\u001b[49m()\n\u001b[1;32m      3\u001b[0m URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://westernu.campuslabs.ca/engage/organizations\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Open the browser\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Chrome' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3\n#### The next step is to scrape the HTML code, and certain elements off the website by using Selenium's \"By\" functions.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this step, we need to know what elements we are looking for and the HTML tags for these elements. We can find this using the developer tools on the browser and selecting the elements you are looking for. For this website, we are specifically looking for the Organization Name, and the Organization Email.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}